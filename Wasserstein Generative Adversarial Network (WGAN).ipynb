{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding and Implementing Wasserstein GAN (WGAN) from Scratch\n",
    "\n",
    "Generative Adversarial Networks (GANs) have become a powerful tool in the realm of deep learning for generating realistic data. One variant of GANs, known as Wasserstein GAN (WGAN), introduces a new perspective on training generators and discriminators. In this blog post, we will delve into the intricacies of WGAN and provide a step-by-step implementation using TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Wasserstein GAN\n",
    "\n",
    "### The Need for Wasserstein GAN\n",
    "\n",
    "Traditional GANs use the binary cross-entropy loss function, which can lead to training instability and mode collapse. Wasserstein GAN addresses these issues by introducing the Wasserstein distance (or Earth Mover's distance) as a more reliable metric for training.\n",
    "\n",
    "### Wasserstein Distance\n",
    "\n",
    "The Wasserstein distance measures the minimum cost of transforming one probability distribution into another. In the context of GANs, it provides a more continuous and stable gradient for the generator and discriminator, allowing for more robust training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "### Loading and Preprocessing Data\n",
    "\n",
    "We start by loading the MNIST dataset, a collection of handwritten digits, and normalizing the pixel values to the range [-1, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Reshape, UpSampling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Generator & Discriminator\n",
    "\n",
    "Next, we define the architecture of the generator and discriminator using TensorFlow/Keras. The generator creates synthetic images, while the critic evaluates the realness of both real and generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the generator model\n",
    "def create_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh', use_bias=False))\n",
    "    model.add(Reshape((28, 28, 1)))  # Reshape to image dimensions\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def create_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "# Create the generator and discriminator models\n",
    "generator = create_generator()\n",
    "discriminator = create_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Generator via WGAN\n",
    "\n",
    "The WGAN model is created by connecting the generator and critic. The generator is trained to generate images that the discriminator classifies as real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Wasserstein GAN model\n",
    "def create_wgan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    wgan_model = Sequential([generator, discriminator])\n",
    "    return wgan_model\n",
    "\n",
    "\n",
    "# Compile the discriminator for Wasserstein GAN\n",
    "discriminator.compile(optimizer=RMSprop(lr=0.00005), loss='mse')\n",
    "\n",
    "# Create the Wasserstein GAN model\n",
    "wgan_model = create_wgan(generator, discriminator)\n",
    "wgan_model.compile(optimizer=RMSprop(lr=0.00005), loss='mse')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "The training loop iterates for a specified number of epochs, updating the critic and generator alternatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the WGAN\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "clip_value = 0.01  # Clip weights to enforce Lipschitz continuity\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train) - batch_size + 1, batch_size):\n",
    "        real_images = x_train[i:i + batch_size]\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = -np.ones((batch_size, 1))\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Clip discriminator weights\n",
    "        for layer in discriminator.layers:\n",
    "            weights = layer.get_weights()\n",
    "            weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "        # Train the generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = wgan_model.train_on_batch(noise, real_labels)\n",
    "\n",
    "    # Print losses at the end of each epoch\n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}')\n",
    "\n",
    "    # Save models every 25th epoch\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        generator.save(f'wgan_generator_epoch_{epoch + 1}.h5')\n",
    "        discriminator.save(f'wgan_discriminator_epoch_{epoch + 1}.h5')\n",
    "\n",
    "# Save the final generator model\n",
    "generator.save('wgan_generator_final.h5')\n",
    "\n",
    "# Save the final discriminator model (optional for evaluation purposes)\n",
    "discriminator.save('wgan_discriminator_final.h5')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Images\n",
    "\n",
    "Finally, the trained generator is used to create synthetic images, and a grid of these images is displayed. The loaded discriminator performs the task of assessing whether an image is genuine or fake. If the output value is in proximity to 0, it signifies that the generated sample is counterfeit. Conversely, if the output value approaches 1, it indicates that the generated sample is authentic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Specify the epoch count, increasing in increments of 25 (with a maximum limit of 200), indicating the training duration for both the generator and discriminator.\n",
    "num_epoch = 200  # Adjust as needed\n",
    "\n",
    "# Load the generator and discriminator models\n",
    "generator = load_model(f'Notebooks/Models/Generator/wgan_generator_epoch_{num_epoch}.h5')\n",
    "discriminator = load_model(f'Notebooks/Models/Discriminator/wgan_discriminator_epoch_{num_epoch}.h5')\n",
    "\n",
    "# Generate a batch of random noise\n",
    "batch_size = 144  # Adjust as needed\n",
    "noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "# Generate images using the generator\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Rescale the generated images to the range [0, 1]\n",
    "generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "# Display the generated images\n",
    "rows, cols = 12, 12  # Adjust as needed\n",
    "fig, axs = plt.subplots(rows, cols)\n",
    "fig.suptitle('Generated Images')\n",
    "idx = 0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axs[i, j].imshow(generated_images[idx].reshape(28, 28), cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        idx += 1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate generated images using the discriminator\n",
    "discriminator_predictions = discriminator.predict(generated_images)\n",
    "\n",
    "# Print discriminator predictions for each generated image\n",
    "for i in range(batch_size):\n",
    "    print(f\"Image {i + 1} - Discriminator Prediction: {discriminator_predictions[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Wasserstein GAN offers a more stable training process compared to traditional GANs. By understanding the Wasserstein distance and implementing it in TensorFlow/Keras, we can create more reliable generators for various applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
