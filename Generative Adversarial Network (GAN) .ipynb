{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN) Model Trained on MNIST Dataset\n",
    "\n",
    "In this notebook, we embark on the creation and training of a Generative Adversarial Network (GAN) using the MNIST dataset. The MNIST dataset is a widely used collection of 28x28 pixel grayscale images of handwritten digits (0 through 9). Each image is labeled with its corresponding digit, making it a popular choice for training and evaluating machine learning models.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "The MNIST dataset consists of 60,000 training images and 10,000 testing images, making it a benchmark dataset for digit recognition tasks. These images are widely employed for developing and testing various machine learning algorithms due to their simplicity and clarity.\n",
    "\n",
    "## Objective of the Notebook\n",
    "\n",
    "Our primary objective is to build a GAN capable of generating realistic-looking handwritten digits similar to those in the MNIST dataset. GANs are known for their ability to create synthetic data by training a generator to produce samples that are indistinguishable from real data, while a discriminator learns to differentiate between real and synthetic samples.\n",
    "\n",
    "## Key Steps in the Notebook\n",
    "\n",
    "1. **Loading and Preprocessing MNIST Data:** We'll start by loading the MNIST dataset and preparing it for training.\n",
    "\n",
    "2. **Defining the Generator and Discriminator Models:** The notebook will guide you through the creation of the generator and discriminator models, crucial components of a GAN.\n",
    "\n",
    "3. **Training the GAN:** We'll train the GAN on the MNIST dataset, allowing the generator to learn how to generate realistic digit images.\n",
    "\n",
    "4. **Evaluating GAN Performance:** We'll assess the quality of the generated images and the overall performance of our GAN model.\n",
    "\n",
    "By the end of this notebook, you'll have a better understanding of GANs and how they can be applied to generate new, authentic-looking digit images based on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "To install the required libraries, you can use the following `%pip` command in your Python environment:\n",
    "\n",
    "\n",
    "This command will install the following libraries:\n",
    "\n",
    "- **NumPy:** A powerful library for numerical operations in Python.\n",
    "- **tqdm:** A fast, extensible progress bar for loops and iterables.\n",
    "- **Matplotlib:** A comprehensive library for creating static, animated, and interactive visualizations in Python.\n",
    "- **TensorFlow:** An open-source machine learning framework developed by Google for building and training machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy tdqm matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of code\n",
    "\n",
    "In this code, we implement a Generative Adversarial Network (GAN) using the TensorFlow library. GANs consist of a generator and a discriminator trained simultaneously, where the generator creates synthetic data, and the discriminator distinguishes between real and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Define the generator model\n",
    "def generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(512, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, activation='tanh', use_bias=False))\n",
    "    return model\n",
    "\n",
    "# Define the discriminator model\n",
    "def discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data(path='mnist.npz')\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "# Create the generator and discriminator models\n",
    "generator = generator()\n",
    "discriminator = discriminator()\n",
    "\n",
    "# Define the optimizers\n",
    "generator_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "discriminator_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999)\n",
    "\n",
    "# Define the loss functions\n",
    "generator_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "discriminator_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "generator.compile(optimizer=generator_optimizer, loss=generator_loss_fn)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss=discriminator_loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Train the GAN\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Use tqdm to create a progress bar for the outer loop\n",
    "    with tqdm(total=len(x_train), desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "        for i in range(0, len(x_train) - batch_size + 1, batch_size):\n",
    "            real_images = x_train[i:i + batch_size]\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            generated_images = generator.predict(noise)\n",
    "\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "            real_loss = discriminator.train_on_batch(real_images, real_labels)\n",
    "            fake_loss = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "            discriminator_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "            # Train the generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            generated_labels = np.ones((batch_size, 1))\n",
    "\n",
    "            with tf.GradientTape() as gen_tape:\n",
    "                generated_images = generator(noise)\n",
    "                fake_output = discriminator(generated_images)\n",
    "                generator_loss = generator_loss_fn(generated_labels, fake_output)\n",
    "\n",
    "            generator_gradients = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "\n",
    "            # Update the generator weights\n",
    "            generator.optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(batch_size)\n",
    "            pbar.set_postfix({'Discriminator Loss': discriminator_loss, 'Generator Loss': generator_loss.numpy()})\n",
    "            \n",
    "# Save the generator model\n",
    "generator.save('generator.h5')\n",
    "\n",
    "# Save the discriminator model\n",
    "discriminator.save('discriminator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Images with the Trained Model\n",
    "\n",
    "Now that we've successfully trained our Generative Adversarial Network (GAN) model and saved the generator as 'generator.h5', let's explore how to generate synthetic images using this trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the generator model\n",
    "generator = load_model('generator.h5')\n",
    "\n",
    "# Generate a batch of random noise\n",
    "noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "# Generate images using the generator\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Rescale the generated images to the range [0, 1]\n",
    "generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "# Display the generated images\n",
    "rows, cols = 4, 4  # Adjust as needed\n",
    "fig, axs = plt.subplots(rows, cols)\n",
    "fig.suptitle('Generated Images')\n",
    "idx = 0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axs[i, j].imshow(generated_images[idx].reshape(28, 28), cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        idx += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating and Evaluating Images with the Discriminator\n",
    "\n",
    "In this section, our objective is to both generate synthetic images and assess their quality by leveraging the discriminator. The following code achieves the dual purpose of image generation and evaluation using the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the generator and discriminator models\n",
    "generator = load_model('generator.h5')\n",
    "discriminator = load_model('discriminator.h5')\n",
    "\n",
    "# Generate a batch of random noise\n",
    "batch_size = 16  # Adjust as needed\n",
    "noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "# Generate images using the generator\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "# Rescale the generated images to the range [0, 1]\n",
    "generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "# Display the generated images\n",
    "rows, cols = 4, 4  # Adjust as needed\n",
    "fig, axs = plt.subplots(rows, cols)\n",
    "fig.suptitle('Generated Images')\n",
    "idx = 0\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axs[i, j].imshow(generated_images[idx].reshape(28, 28), cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "        idx += 1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate generated images using the discriminator\n",
    "discriminator_predictions = discriminator.predict(generated_images)\n",
    "\n",
    "# Print discriminator predictions for each generated image\n",
    "for i in range(batch_size):\n",
    "    print(f\"Image {i + 1} - Discriminator Prediction: {discriminator_predictions[i][0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
